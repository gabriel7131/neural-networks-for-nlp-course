{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free-form project: Multilabel Classification\n",
    "\n",
    "At this point, we have learned how to:\n",
    "\n",
    "1. Load, preprocess and vectorize text documents for text classification.\n",
    "2. Design neural architectures that can deal with structured documents.\n",
    "3. Load pretrained embedding matrices, or train our own word embeddings.\n",
    "4. Perform binary and multi-class classification tasks.\n",
    "\n",
    "So what's left? Well, of course the sky is the limit! What we have seen is nothing but a primer, an initial set of ideas that let us tackle projects on our own. With that in mind, and since now you understand how to build your own models, it is time to let you roam freely. \n",
    "\n",
    "This project is your first wheels-off Natural Language Processing project using Neural Networks. The notebook is organized so that you can also see a general structure for a project — but you could do this differently, and in some cases you will need to! Let's jump into the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackExchange — Predicting cooking tags!\n",
    "\n",
    "Programmers love StackOverflow, both seasoned and rookies alike. The site needs no introduction: you might have even browsed it searching for answers during this course! StackExchange is the same thing, but extended to other domains: cooking, languages, politics, history, travelling, riddles, you name it! \n",
    "\n",
    "In our project, we will try to predict the tags on posts in the Cooking StackExchange site, called 'Seasoned Advice'. A post can have multiple tags, so multiclass classification will not work for us in this case. Furthermore, it should be obvious that there are many possible such tags. To make the task easier, the dataset you will be using is already preprocessed so that:\n",
    "\n",
    "* You will only work 300 most frequent tags\n",
    "* Documents have been cleaned and lowercased, removing HTML markup, punctuation and straneous whitespace.\n",
    "* Untagged documents are removed.\n",
    "\n",
    "Your project must:\n",
    "\n",
    "  1. Load and vectorize the data, computing the label set and the vocabulary. \n",
    "  2. Split the data into training and validation sets, so you can check the quality of your model on unseen data. \n",
    "  3. Design a neural architecture that is suited for the project.\n",
    "  4. Prepare the training pipeline, and fully train a model.\n",
    "  5. Select appropriate metrics and evaluate the model. \n",
    "  6. Analyze the results and find ways to improve labels for which your model does poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "dataset = []\n",
    "with io.open('se_cooking.tsv', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        tags, body = line.split('\\t')\n",
    "        tags = tags.split('|')\n",
    "        instance = (tags, body)\n",
    "        dataset.append(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before delving into the project, let's take a look at a few documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cooking StackExchange Dataset — Quickview:')\n",
    "print('------------------------------------------\\n')\n",
    "for (tags, body) in dataset[:3]:\n",
    "    print('\"{}\"\\n\\n\\t\\t is tagged with: {}\\n'.format(body.strip(), ', '.join(tags)))\n",
    "    print('------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation — Indexing and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data here.\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Prepare a token vocabulary.\n",
    "#   2. Prepare a label-indices dictionary.\n",
    "#   3. Process the label sets to become vectors.\n",
    "#   4. Process the bodies to be vocabulary index lists.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   What should be the maximum document length?\n",
    "#   What should be done with uncommon words?\n",
    "#   Which kind of model will you be using? Does that affect the preprocessing steps?\n",
    "#\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation — Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data here.\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Select a split ratio.\n",
    "#   2. Extract instances by the chosen, indexing by a random shuffle of all the possible indices.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   What happens to very small classes with the ratio you chose?\n",
    "#   What could you do to better sample the classes?\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design — Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design your model here.\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Select a kind of input:\n",
    "#     - Bag of Words\n",
    "#     - Word Embeddings\n",
    "#   2. Design a suitable network, using architectures seen in the course:\n",
    "#     - Deep Neural Network\n",
    "#     - Convolutional Neural Network\n",
    "#     - Recurrent Neural Network\n",
    "#   3. Select the network output — since it is a MULTILABEL problem, more than one label may fire for a document.\n",
    "#     - Use an appropriate loss.\n",
    "#     - Use as many output units as there are labels.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   Which model is more likely to do well in this situation? Do we have many documents? \n",
    "#   If we generalized the input to all StackExchange sites, which model would make the most sense?\n",
    "#\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Input, Dense, LSTM, Bidirectional, Embedding\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPool2D, AvgPool2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design — Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model here.\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Select a batch size.\n",
    "#   2. Decide which metrics to report.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   Can you implement your own metrics to evaluate as it trains?\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation — Metrics and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model here\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Select a set of metrics that makes sense — for instance:\n",
    "#     * precision\n",
    "#     * recall\n",
    "#     * F1 score.\n",
    "#   2. Evaluate them on the output of the model.\n",
    "#   3. Find out which classes perform better than others.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   Which metrics make sense for a multi-label problem? \n",
    "#   Conversely, which metrics do NOT make sense for a multi-label problem? Why? \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation — Analysis and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance here\n",
    "#\n",
    "#  TIPS:\n",
    "#\n",
    "#   1. Try visualizing per-class performance and creating an easy way for you to look at documents.\n",
    "#   2. Figure out why some classes underperform: \n",
    "#     * is it because of a lack of data? \n",
    "#     * is it due to noise in the data?\n",
    "#   3. Think of ways to solve the problem.\n",
    "#\n",
    "#  Questions:\n",
    "#\n",
    "#   None! This is the most broad, open, fun and —at times— frustrating part of the whole process!\n",
    "#   If you've managed to get there, congratulations: you've already learnt a lot!\n",
    "#   Now onwards — improve the model more!\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
